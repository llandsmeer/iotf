<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>ioperf.model API documentation</title>
<meta name="description" content="Inferior olive model from de Gruijl et al.
implemented in tensorflow and helper functions
for optimization and network generation." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ioperf.model</code></h1>
</header>
<section id="section-intro">
<p>Inferior olive model from de Gruijl et al.
implemented in tensorflow and helper functions
for optimization and network generation.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Inferior olive model from de Gruijl et al.
implemented in tensorflow and helper functions
for optimization and network generation.
&#39;&#39;&#39;

from .make_tf_function import make_tf_function
from .make_initial_neuron_state import make_initial_neuron_state
from .sample_connections_3d import sample_connections_3d
from .timestep import timestep
from .make_onnx_model import make_onnx_model

__all__ = [
        &#39;make_tf_function&#39;,
        &#39;make_initial_neuron_state&#39;,
        &#39;sample_connections_3d&#39;,
        &#39;timestep&#39;,
        &#39;make_onnx_model&#39;
        ]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ioperf.model.make_initial_neuron_state"><code class="name flex">
<span>def <span class="ident">make_initial_neuron_state</span></span>(<span>ncells, V_soma=-60.0, soma_k=0.7423159, soma_l=0.0321349, soma_h=0.3596066, soma_n=0.2369847, soma_x=0.1, V_axon=-60.0, axon_Sodium_h=0.9, axon_Potassium_x=0.2369847, V_dend=-60.0, dend_Ca2Plus=3.715, dend_Calcium_r=0.0113, dend_Potassium_s=0.0049291, dend_Hcurrent_q=0.0337836, dtype=tf.float32)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_initial_neuron_state(
        ncells,

        # Soma State
        V_soma          = -60.0,
        soma_k          =   0.7423159,
        soma_l          =   0.0321349,
        soma_h          =   0.3596066,
        soma_n          =   0.2369847,
        soma_x          =   0.1,

        # Axon state
        V_axon          = -60.0,
        axon_Sodium_h   =   0.9,
        axon_Potassium_x=   0.2369847,

        # Dend state
        V_dend          = -60.0,
        dend_Ca2Plus    =   3.715,
        dend_Calcium_r  =   0.0113,
        dend_Potassium_s=   0.0049291,
        dend_Hcurrent_q =   0.0337836,
        dtype=tf.float32):

    return tf.constant([

        # Soma state
        [V_soma]*ncells if V_soma is not None else np.random.normal(-60, 3, ncells),
        [soma_k]*ncells if soma_k is not None else np.random.random(ncells),
        [soma_l]*ncells if soma_l is not None else np.random.random(ncells),
        [soma_h]*ncells if soma_h is not None else np.random.random(ncells),
        [soma_n]*ncells if soma_n is not None else np.random.random(ncells),
        [soma_x]*ncells if soma_x is not None else np.random.random(ncells),

        # Axon state
        [V_axon]*ncells if V_axon is not None else np.random.normal(-60, 3, ncells),
        [axon_Sodium_h]*ncells if axon_Sodium_h is not None else np.random.random(ncells),
        [axon_Potassium_x]*ncells if axon_Potassium_x is not None else np.random.random(ncells),

        # Dend state
        [V_dend]*ncells if V_dend is not None else np.random.normal(-60, 3, ncells),
        [dend_Ca2Plus]*ncells,
        [dend_Calcium_r]*ncells if dend_Calcium_r is not None else np.random.random(ncells),
        [dend_Potassium_s]*ncells if dend_Potassium_s is not None else np.random.random(ncells),
        [dend_Hcurrent_q]*ncells if dend_Hcurrent_q is not None else np.random.random(ncells),

        ], dtype=dtype)</code></pre>
</details>
</dd>
<dt id="ioperf.model.make_onnx_model"><code class="name flex">
<span>def <span class="ident">make_onnx_model</span></span>(<span>*args, opset=16, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This function takes the same arguments as the make_tf_function call
and returns the path to the ONNX model.
Optionally, one can specify an extra <code>opset</code> argument for ONNX</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_onnx_model(*args, opset=16, **kwargs):
    &#39;&#39;&#39;
    This function takes the same arguments as the make_tf_function call
    and returns the path to the ONNX model.
    Optionally, one can specify an extra `opset` argument for ONNX
    &#39;&#39;&#39;
    tf_function = model.make_tf_function(*args, **kwargs)
    path = tempfile.mktemp() + &#39;.onnx&#39;

    onnx_model, _ = tf2onnx.convert.from_function(
            function=tf_function, 
            input_signature=tf_function.argspec,
            output_path=path,
            opset=opset,
            )

    return path</code></pre>
</details>
</dd>
<dt id="ioperf.model.make_tf_function"><code class="name flex">
<span>def <span class="ident">make_tf_function</span></span>(<span>*, ngj=0, ncells=None, argconfig=(), unroll_gj=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Build an optimized timestep tensorflow function.</p>
<p><code>ngj</code>: number of gap junctions (either 0 or len(output of sample_connections_3d)</p>
<p>When <code>ngj</code> is non-zero, the resulting function expects an extra set of parameters</p>
<p><code>gj_src</code>, <code>gj_tgt</code> and <code>g_gj</code></p>
<p><code>ncells</code>: number of neurons</p>
<p><code>argconfig</code>: a dictionary of argument configuration.</p>
<p>keys correspond to model parameters, and can be chosen from</p>
<p><code>g_int</code>, <code>p1</code>, <code>p2</code>, <code>g_CaL</code>, <code>g_h</code>, <code>g_K_Ca</code>,
<code>g_ld</code>, <code>g_la</code>, <code>g_ls</code>, <code>g_Na_s</code>, <code>g_Kdr_s</code>, <code>g_K_s</code>,
<code>g_CaH</code>, <code>g_Na_a</code>, <code>g_K_a</code>, <code>V_Na</code>, <code>V_K</code>, <code>V_Ca</code>,
<code>V_h</code>, <code>V_l</code>, <code>I_app</code>, <code>delta</code></p>
<p>values can be</p>
<ul>
<li><code>'CONSTANT'</code>: when calling the resulting function you provide
a single number which will be constant parameter across all cells</li>
<li><code>'VARY'</code>: when calling the resulting function you provide an array
of length <code>ncells</code> with the parameter values for each cell</li>
<li>a numerical value (float or int): a single constant value to
be compiled into the model (hopefully optimized out)</li>
</ul>
<p>The resulting function will always require the <code>state</code> argument,
initially generated by the make_initial_neuron_state() function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_tf_function(*, ngj=0, ncells=None, argconfig=(), unroll_gj=0):
    &#39;&#39;&#39;
    Build an optimized timestep tensorflow function.

    `ngj`: number of gap junctions (either 0 or len(output of sample_connections_3d)

    When `ngj` is non-zero, the resulting function expects an extra set of parameters

    `gj_src`, `gj_tgt` and `g_gj`

    `ncells`: number of neurons

    `argconfig`: a dictionary of argument configuration.

    keys correspond to model parameters, and can be chosen from

    `g_int`, `p1`, `p2`, `g_CaL`, `g_h`, `g_K_Ca`,
    `g_ld`, `g_la`, `g_ls`, `g_Na_s`, `g_Kdr_s`, `g_K_s`,
    `g_CaH`, `g_Na_a`, `g_K_a`, `V_Na`, `V_K`, `V_Ca`,
    `V_h`, `V_l`, `I_app`, `delta`

    values can be

     - `&#39;CONSTANT&#39;`: when calling the resulting function you provide
       a single number which will be constant parameter across all cells
     - `&#39;VARY&#39;`: when calling the resulting function you provide an array
       of length `ncells` with the parameter values for each cell
     - a numerical value (float or int): a single constant value to
       be compiled into the model (hopefully optimized out)

    The resulting function will always require the `state` argument,
    initially generated by the make_initial_neuron_state() function.
    &#39;&#39;&#39;
    MAKE_FUNCTION_TEMPLATE = &#39;@tf.function\ndef wrapper({function_args}): return {{&#34;state_next&#34;:timestep({call_args})}}&#39;
    argconfig = dict(argconfig)
    cell_params = [&#39;g_int&#39;, &#39;p1&#39;, &#39;p2&#39;, &#39;g_CaL&#39;, &#39;g_h&#39;, &#39;g_K_Ca&#39;,
                  &#39;g_ld&#39;, &#39;g_la&#39;, &#39;g_ls&#39;, &#39;g_Na_s&#39;, &#39;g_Kdr_s&#39;, &#39;g_K_s&#39;,
                  &#39;g_CaH&#39;, &#39;g_Na_a&#39;, &#39;g_K_a&#39;, &#39;V_Na&#39;, &#39;V_K&#39;, &#39;V_Ca&#39;,
                  &#39;V_h&#39;, &#39;V_l&#39;, &#39;I_app&#39;, &#39;delta&#39; ]
    function_args = [&#39;state&#39;] # generated function signature in python
    call_args = [&#39;state&#39;] # call arguments to timestep()
    argspec = [tf.TensorSpec((NUM_STATE_VARS, ncells), tf.float32, name=&#39;state&#39;)] # TensorFlow argspec
    for param in cell_params:
        if param not in argconfig:
            continue
        value = argconfig.pop(param)
        if isinstance(value, (float, int)):
            call_args.append(f&#39;{param}={value}&#39;)
        elif value == &#39;CONSTANT&#39;:
            function_args.append(param)
            call_args.append(f&#39;{param}={param}&#39;)
            argspec.append(tf.TensorSpec((), tf.float32, name=param))
        elif value == &#39;VARY&#39;:
            function_args.append(param)
            call_args.append(f&#39;{param}={param}&#39;)
            argspec.append(tf.TensorSpec((ncells,), tf.float32, name=param))
        else:
            raise ValueError(f&#39;Unknown argconfig {param}={repr(value)}. Must be float, int, &#34;CONSTANT&#34; or &#34;VARY&#34;&#39;)
    if argconfig:
        raise ValueError(f&#39;Leftover argconfig {argconfig}&#39;)
    if ngj != 0:
        for arg in &#39;gj_src&#39;, &#39;gj_tgt&#39;, &#39;g_gj&#39;:
            function_args.append(arg)
            call_args.append(f&#39;{arg}={arg}&#39;)
        argspec.append(tf.TensorSpec(ngj, tf.int32, name=&#39;gj_src&#39;))
        argspec.append(tf.TensorSpec(ngj, tf.int32, name=&#39;gj_tgt&#39;))
        argspec.append(tf.TensorSpec((), tf.float32, name=&#39;g_gj&#39;))

    call_args.append(f&#39;unroll_gj={int(unroll_gj)}&#39;)

    function_args = &#39;, &#39;.join(function_args)
    call_args = &#39;, &#39;.join(call_args)

    final = MAKE_FUNCTION_TEMPLATE.format(function_args=function_args, call_args=call_args)
    env = dict(
        tf = tf,
        timestep=timestep
    )
    exec(final, env)
    wrapper = env[&#39;wrapper&#39;]
    wrapper.argspec = argspec
    return wrapper</code></pre>
</details>
</dd>
<dt id="ioperf.model.sample_connections_3d"><code class="name flex">
<span>def <span class="ident">sample_connections_3d</span></span>(<span>nneurons, nconnections=10, rmax=2, connection_probability=&lt;function &lt;lambda&gt;&gt;, normalize_by_dr=True)</span>
</code></dt>
<dd>
<div class="desc"><p>(Gaussian) connection sampling in a cube. <code>nneurons</code> must thus
be a power of 3 integer. <code>nconnections</code> is
amount of connections
per neuron. Values in the range of 10 are biologically plausible.
<code>rmax</code> determines the maximum radial distance considered.
The <code>connection_probability</code> is a function that determines the
PDF, it will be normalized according to <code>rmax</code> and uneven radial point
distribution in a 3d lattice.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_connections_3d(
        nneurons,
        nconnections=10,
        rmax=2,
        connection_probability=lambda r: np.exp(-(r/4)**2),
        normalize_by_dr=True
        ):
    &#39;&#39;&#39;
    (Gaussian) connection sampling in a cube. `nneurons` must thus
    be a power of 3 integer. `nconnections` is  amount of connections
    per neuron. Values in the range of 10 are biologically plausible.
    `rmax` determines the maximum radial distance considered.
    The `connection_probability` is a function that determines the
    PDF, it will be normalized according to `rmax` and uneven radial point
    distribution in a 3d lattice.
    &#39;&#39;&#39;
    assert int(round(nneurons**(1/3)))**3 == nneurons
    # we sample half the connections for each neuron
    assert nconnections % 2 == 0
    # we assume a cubic (4d toroid) brain
    nside = int(np.ceil(nneurons**(1/3)))
    if rmax &gt; nside / 2: rmax = nside // 2
    # we set up a connection probability kernel around each neuron
    dx, dy, dz = np.mgrid[-rmax:rmax+1, -rmax:rmax+1, -rmax:rmax+1]
    dx, dy, dz = dx.flatten(), dy.flatten(), dz.flatten()
    r = np.sqrt(dx*dx + dy*dy + dz*dz)
    # we only sample backwards, as the forward connections
    # are part of the kernel of other neurons
    sample_backwards = \
            ((dz &lt; 0)) | \
            ((dz == 0) &amp;( dy &lt; 0)) | \
            ((dz == 0) &amp; (dy == 0) &amp; (dx &lt; 0))
    m = (r != 0) &amp; sample_backwards &amp; (r &lt; rmax)
    dx, dy, dz, r = dx[m], dy[m], dz[m], r[m]
    P = connection_probability(r)

    # next, there is a ~r^2 increase in point density per r,
    # and very non uniform distribution of those due to
    # the integer grid. let&#39;s remove that bias
    ro, r_uniq_idx = np.unique(r, return_inverse=True)
    r_idx_freq = np.bincount(r_uniq_idx)
    r_freq = r_idx_freq[r_uniq_idx]
    P = P / r_freq
    if normalize_by_dr:
        dr = 0.5*np.diff(ro, append=rmax)[r_uniq_idx] + 0.5*np.diff(ro, prepend=0)[r_uniq_idx]
        P = P * dr
    # P must sum up to 1
    P = P / P.sum()

    # a connection connects two neurons
    final_connection_count = nneurons * nconnections // 2

    # instead of sampling using the P array,
    # we sample for each value of the P array,
    # which is much more memory efficient
    counts = (P * final_connection_count + .5).astype(int)
    counts[-1] =  max(0, final_connection_count - counts[:-1].sum())
    assert (counts &lt; nneurons).all()
    conn_idx = []
    for draw in range(len(P)):
        if counts[draw] == 0:
            continue
        if counts[draw] == 1:
            draw_idx = np.array([np.random.randint(nneurons)])
        else:
            draw_idx = np.random.choice(nneurons, counts[draw], replace=False)
        conn_idx.append(draw + len(P) * draw_idx)
    conn_idx = np.concatenate(conn_idx)

    # now we calculate the neuron indices back from the P kernel
    neuron_id1 = conn_idx // len(P)
    x = ( neuron_id1 %  nside).astype(&#39;int32&#39;)
    y = ((neuron_id1 // nside) % nside).astype(&#39;int32&#39;)
    z = ((neuron_id1 // (nside*nside)) % nside).astype(&#39;int32&#39;)

    di = conn_idx % len(P)

    neuron_id2 = ( \
        (x + dx[di]) % nside + \
        (y + dy[di]) % nside * nside + \
        (z + dz[di]) % nside * nside * nside
        ).astype(int)

    # and generate the final index arrays
    # needed for gj calculation
    tgt_idx = np.concatenate([neuron_id1, neuron_id2])
    src_idx = np.concatenate([neuron_id2, neuron_id1])

    return tf.constant(src_idx, dtype=&#39;int32&#39;), \
           tf.constant(tgt_idx, dtype=&#39;int32&#39;)</code></pre>
</details>
</dd>
<dt id="ioperf.model.timestep"><code class="name flex">
<span>def <span class="ident">timestep</span></span>(<span>state, delta=0.025, g_int=0.13, p1=0.25, p2=0.15, g_CaL=1.1, g_h=0.12, g_K_Ca=35.0, g_ld=0.01532, g_la=0.016, g_ls=0.016, g_Na_s=150.0, g_Kdr_s=9.0, g_K_s=5.0, g_CaH=4.5, g_Na_a=240.0, g_K_a=240.0, S=1.0, V_Na=55.0, V_K=-75.0, V_Ca=120.0, V_h=-43.0, V_l=10.0, I_app=0.0, gj_src=None, gj_tgt=None, g_gj=0.05, unroll_gj=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Raw python implementation of the IO model using tensorflow math functions.
Don't call this function directly, instead use make_tf_function() to
optimize out unused parameters and compile to a tf.function for later use.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def timestep(
        state,

        # Simulation parameters
        delta=0.025,

        # Geometry parameters
        g_int           =   0.13,    # Cell internal conductance  -- now a parameter (0.13)
        p1              =   0.25,    # Cell surface ratio soma/dendrite
        p2              =   0.15,    # Cell surface ratio axon(hillock)/soma

        # Channel conductance parameters
        g_CaL           =   1.1,     # Calcium T - (CaV 3.1) (0.7)
        g_h             =   0.12,    # H current (HCN) (0.4996)
        g_K_Ca          =  35.0,     # Potassium  (KCa v1.1 - BK) (35)
        g_ld            =   0.01532, # Leak dendrite (0.016)
        g_la            =   0.016,   # Leak axon (0.016)
        g_ls            =   0.016,   # Leak soma (0.016)
        g_Na_s          = 150.0,     # Sodium  - (Na v1.6 )
        g_Kdr_s         =   9.0,     # Potassium - (K v4.3)
        g_K_s           =   5.0,     # Potassium - (K v3.4)
        g_CaH           =   4.5,     # High-threshold calcium -- Ca V2.1
        g_Na_a          = 240.0,     # Sodium
        g_K_a           = 240.0,     # Potassium (20)

        # Membrane capacitance
        S               =   1.0,     # 1/C_m, cm^2/uF

        # Reversal potential parameters
        V_Na            =  55.0,     # Sodium
        V_K             = -75.0,     # Potassium
        V_Ca            = 120.0,     # Low-threshold calcium channel
        V_h             = -43.0,     # H current
        V_l             =  10.0,     # Leak

        # Stimulus parameter
        I_app           =   0.0,
        gj_src          = None,
        gj_tgt          = None,
        g_gj            = 0.05,
        unroll_gj       = 0
        ):
    &#39;&#39;&#39;
    Raw python implementation of the IO model using tensorflow math functions.
    Don&#39;t call this function directly, instead use make_tf_function() to
    optimize out unused parameters and compile to a tf.function for later use.
    &#39;&#39;&#39;

    assert state.shape[0] == NUM_STATE_VARS

    # Soma state
    V_soma              = state[0, :]
    soma_k              = state[1, :]
    soma_l              = state[2, :]
    soma_h              = state[3, :]
    soma_n              = state[4, :]
    soma_x              = state[5, :]

    # Axon state
    V_axon              = state[6, :]
    axon_Sodium_h       = state[7, :]
    axon_Potassium_x    = state[8, :]

    # Dend state
    V_dend              = state[9, :]
    dend_Ca2Plus        = state[10,:]
    dend_Calcium_r      = state[11,:]
    dend_Potassium_s    = state[12,:]
    dend_Hcurrent_q     = state[13,:]

    ########## SOMA UPDATE ##########

    # CURRENT: Soma leak current (ls)
    soma_I_leak        = g_ls * (V_soma - V_l)

    # CURRENT: Soma interaction current (ds, as)
    I_ds        =  (g_int / p1)        * (V_soma - V_dend)
    I_as        =  (g_int / (1 - p2))  * (V_soma - V_axon)
    soma_I_interact =  I_ds + I_as

    # CHANNEL: Soma Low-threshold calcium (CaL)
    soma_Ical   = g_CaL * soma_k * soma_k * soma_k * soma_l * (V_soma - V_Ca)

    soma_k_inf  = 1 / (1 + tf.exp(-(V_soma + 61)/4.2))
    soma_l_inf  = 1 / (1 + tf.exp( (V_soma + 85)/8.5))
    soma_tau_l  = (20 * tf.exp((V_soma + 160)/30) / (1 + tf.exp((V_soma + 84) / 7.3))) + 35

    soma_dk_dt  = soma_k_inf - soma_k
    soma_dl_dt  = (soma_l_inf - soma_l) / soma_tau_l

    # CHANNEL: Soma sodium (Na_s)
    # watch out direct gate: m = m_inf
    soma_m_inf  = 1 / (1 + tf.exp(-(V_soma + 30)/5.5))
    soma_h_inf  = 1 / (1 + tf.exp( (V_soma + 70)/5.8))
    soma_Ina    = g_Na_s * soma_m_inf**3 * soma_h * (V_soma - V_Na)
    soma_tau_h  = 3 * tf.exp(-(V_soma + 40)/33)
    soma_dh_dt  = (soma_h_inf - soma_h) / soma_tau_h

    # CHANNEL: Soma potassium, slow component (Kdr)
    soma_Ikdr   = g_Kdr_s * soma_n**4 * (V_soma - V_K)
    soma_n_inf  = 1 / ( 1 + tf.exp(-(V_soma +  3)/10))
    soma_tau_n  = 5 + (47 * tf.exp( (V_soma + 50)/900))
    soma_dn_dt  = (soma_n_inf - soma_n) / soma_tau_n

    # CHANNEL: Soma potassium, fast component (K_s)
    soma_Ik      = g_K_s * soma_x**4 * (V_soma - V_K)
    soma_alpha_x = 0.13 * (V_soma + 25) / (1 - tf.exp(-(V_soma + 25)/10))
    soma_beta_x  = 1.69 * tf.exp(-(V_soma + 35)/80)
    soma_tau_x_inv=soma_alpha_x + soma_beta_x
    soma_x_inf   = soma_alpha_x / soma_tau_x_inv

    soma_dx_dt   = (soma_x_inf - soma_x) * soma_tau_x_inv

    # UPDATE: Soma compartment update (V_soma)
    soma_I_Channels = soma_Ik + soma_Ikdr + soma_Ina + soma_Ical
    soma_dv_dt = S * (-(soma_I_leak + soma_I_interact + soma_I_Channels))

    ########## AXON UPDATE ##########

    # CURRENT: Axon leak current (la)
    axon_I_leak    =  g_la * (V_axon - V_l)

    # CURRENT: Axon interaction current (sa)
    I_sa           =  (g_int / p2) * (V_axon - V_soma)
    axon_I_interact=  I_sa

    # CHANNEL: Axon sodium (Na_a)
    # watch out direct gate: m = m_inf
    axon_m_inf     =  1 / (1 + tf.exp(-(V_axon+30)/5.5))
    axon_h_inf     =  1 / (1 + tf.exp( (V_axon+60)/5.8))
    axon_Ina       =  g_Na_a * axon_m_inf**3 * axon_Sodium_h * (V_axon - V_Na)
    axon_tau_h     =  1.5 * tf.exp(-(V_axon+40)/33)
    axon_dh_dt     =  (axon_h_inf - axon_Sodium_h) / axon_tau_h

    # CHANNEL: Axon potassium (K_a)
    axon_Ik        =  g_K_a * axon_Potassium_x**4 * (V_axon - V_K)
    axon_alpha_x   =  0.13*(V_axon + 25) / (1 - tf.exp(-(V_axon + 25)/10))
    axon_beta_x    =  1.69 * tf.exp(-(V_axon + 35)/80)
    axon_tau_x_inv =  axon_alpha_x + axon_beta_x
    axon_x_inf     =  axon_alpha_x / axon_tau_x_inv
    axon_dx_dt     =  (axon_x_inf - axon_Potassium_x) * axon_tau_x_inv

    # UPDATE: Axon hillock compartment update (V_axon)
    axon_I_Channels = axon_Ina + axon_Ik
    axon_dv_dt  = S * (-(axon_I_leak +  axon_I_interact + axon_I_Channels))

    ########## DEND UPDATE ##########

    # CURRENT: Dend application current (I_app)

    if unroll_gj == 0 and (gj_src is not None and gj_tgt is not None):
        vdiff = tf.gather(V_dend, gj_src) - tf.gather(V_dend, gj_tgt)
        cx36_current_per_gj = (0.2 + 0.8 * tf.exp(-vdiff*vdiff / 100)) * vdiff * g_gj
        I_gapp = tf.tensor_scatter_nd_add(tf.zeros_like(V_dend), tf.reshape(gj_tgt, (-1, 1)),
            cx36_current_per_gj)
    elif gj_src is not None and gj_tgt is not None:
        I_gapp = 0
        for i in range(0, gj_src.shape[0], unroll_gj):
            end = min(i + unroll_gj, gj_src.shape[0])
            vdiff = tf.gather(V_dend, gj_src[i:end]) - tf.gather(V_dend, gj_tgt[i:end])
            cx36_current_per_gj = (0.2 + 0.8 * tf.exp(-vdiff*vdiff / 100)) * vdiff * g_gj
            I_gapp += tf.tensor_scatter_nd_add(tf.zeros_like(V_dend), tf.reshape(gj_tgt[i:end], (-1, 1)), cx36_current_per_gj)
    else:
        I_gapp = 0

    dend_I_application = -I_app - I_gapp

    # CURRENT: Dend leak current (ld)
    dend_I_leak     =  g_ld * (V_dend - V_l)

    # CURRENT: Dend interaction Current (sd)
    dend_I_interact =  (g_int / (1 - p1)) * (V_dend - V_soma)

    # CHANNEL: Dend high-threshold calcium (CaH)
    dend_Icah       =  g_CaH * dend_Calcium_r * dend_Calcium_r * (V_dend - V_Ca)
    dend_alpha_r    =  1.7 / (1 + tf.exp(-(V_dend - 5)/13.9))
    dend_beta_r     =  0.02*(V_dend + 8.5) / (tf.exp((V_dend + 8.5)/5) - 1.0)
    dend_tau_r_inv5 =  (dend_alpha_r + dend_beta_r) # tau = 5 / (alpha + beta)
    dend_r_inf      =  dend_alpha_r / dend_tau_r_inv5
    dend_dr_dt      =  (dend_r_inf - dend_Calcium_r) * dend_tau_r_inv5 * 0.2

    # CHANNEL: Dend calcium dependent potassium (KCa)
    dend_Ikca       =  g_K_Ca * dend_Potassium_s * (V_dend - V_K)
    dend_alpha_s    =  tf.where(
            0.00002 * dend_Ca2Plus &lt; 0.01,
            0.00002 * dend_Ca2Plus,
            0.01)
    dend_tau_s_inv  =  dend_alpha_s + 0.015
    dend_s_inf      =  dend_alpha_s / dend_tau_s_inv
    dend_ds_dt      =  (dend_s_inf - dend_Potassium_s) * dend_tau_s_inv

    # CHANNEL: Dend proton (h)
    dend_Ih         =  g_h * dend_Hcurrent_q * (V_dend - V_h)
    q_inf           =  1 / (1 + tf.exp((V_dend + 80)/4))
    tau_q_inv       =  tf.exp(-0.086*V_dend - 14.6) + tf.exp(0.070*V_dend - 1.87)
    dend_dq_dt      =  (q_inf - dend_Hcurrent_q) * tau_q_inv

    # CONCENTRATION: Dend calcium concentration (CaPlus)
    dend_dCa_dt          =  -3 * dend_Icah - 0.075 * dend_Ca2Plus

    # UPDATE: Dend compartment update (V_dend)
    dend_I_Channels = dend_Icah + dend_Ikca + dend_Ih
    dend_dv_dt  = S * (-(dend_I_leak +  dend_I_interact + dend_I_application + dend_I_Channels))

    ########## UPDATE ##########

    return tf.stack([
        # Soma state
        V_soma              + soma_dv_dt * delta,
        soma_k              + soma_dk_dt * delta,
        soma_l              + soma_dl_dt * delta,
        soma_h              + soma_dh_dt * delta,
        soma_n              + soma_dn_dt * delta,
        soma_x              + soma_dx_dt * delta,
        # Axon state
        V_axon              + axon_dv_dt * delta,
        axon_Sodium_h       + axon_dh_dt * delta,
        axon_Potassium_x    + axon_dx_dt * delta,
        # Dend state
        V_dend              + dend_dv_dt * delta,
        dend_Ca2Plus        + dend_dCa_dt* delta,
        dend_Calcium_r      + dend_dr_dt * delta,
        dend_Potassium_s    + dend_ds_dt * delta,
        dend_Hcurrent_q     + dend_dq_dt * delta,
        ], axis=0)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ioperf" href="../index.html">ioperf</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ioperf.model.make_initial_neuron_state" href="#ioperf.model.make_initial_neuron_state">make_initial_neuron_state</a></code></li>
<li><code><a title="ioperf.model.make_onnx_model" href="#ioperf.model.make_onnx_model">make_onnx_model</a></code></li>
<li><code><a title="ioperf.model.make_tf_function" href="#ioperf.model.make_tf_function">make_tf_function</a></code></li>
<li><code><a title="ioperf.model.sample_connections_3d" href="#ioperf.model.sample_connections_3d">sample_connections_3d</a></code></li>
<li><code><a title="ioperf.model.timestep" href="#ioperf.model.timestep">timestep</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>